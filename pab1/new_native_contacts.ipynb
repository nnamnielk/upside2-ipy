{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Native Contacts Analysis\n",
    "\n",
    "Functions to load hydrogen bond analysis results and convert to pandas DataFrames for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hbond_data_to_dataframe(file_prefix, results_dir=\"results/\", show_timing=False):\n",
    "    \"\"\"\n",
    "    Load hydrogen bond analysis results and convert to pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        file_prefix: e.g. \"Kmarx_Pab1.run.0\"\n",
    "        results_dir: directory containing the results files\n",
    "        show_timing: whether to print timing information\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame with columns:\n",
    "        - frame: trajectory frame number\n",
    "        - residue_i: first residue index\n",
    "        - residue_j: second residue index  \n",
    "        - hbond_energy: hydrogen bond energy between residues\n",
    "        - run_id: extracted from filename for identification\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Construct file paths\n",
    "    npy_file = Path(results_dir) / f\"{file_prefix}_hbond_energy_maps.npy\"\n",
    "    pkl_file = Path(results_dir) / f\"{file_prefix}_hbond_results.pkl\"\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not npy_file.exists():\n",
    "        raise FileNotFoundError(f\"Energy maps file not found: {npy_file}\")\n",
    "    if not pkl_file.exists():\n",
    "        raise FileNotFoundError(f\"Results file not found: {pkl_file}\")\n",
    "    \n",
    "    # Load data\n",
    "    load_start = time.time()\n",
    "    energy_maps = np.load(npy_file)  # Shape: (n_frames, n_residues, n_residues)\n",
    "    \n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    load_time = time.time() - load_start\n",
    "    \n",
    "    n_frames, n_residues, _ = energy_maps.shape\n",
    "    \n",
    "    # Extract run_id from file_prefix\n",
    "    run_id = file_prefix.split('.')[-1] if '.' in file_prefix else file_prefix\n",
    "    \n",
    "    # Convert to long format DataFrame\n",
    "    process_start = time.time()\n",
    "    data_rows = []\n",
    "    \n",
    "    for frame in range(n_frames):\n",
    "        for i in range(n_residues):\n",
    "            for j in range(i+1, n_residues):  # Only upper triangle to avoid duplicates\n",
    "                energy = energy_maps[frame, i, j]\n",
    "                if energy > 1e-6:  # Only include meaningful interactions\n",
    "                    data_rows.append({\n",
    "                        'frame': frame,\n",
    "                        'residue_i': i,\n",
    "                        'residue_j': j,\n",
    "                        'hbond_energy': energy,\n",
    "                        'run_id': run_id\n",
    "                    })\n",
    "    \n",
    "    df = pd.DataFrame(data_rows)\n",
    "    process_time = time.time() - process_start\n",
    "    \n",
    "    # Add metadata as attributes\n",
    "    df.attrs = {\n",
    "        'n_donors': len(metadata['donors']),\n",
    "        'n_acceptors': len(metadata['acceptors']),\n",
    "        'n_residues': metadata['n_residues'],\n",
    "        'n_frames': metadata['n_frames'],\n",
    "        'file_prefix': file_prefix\n",
    "    }\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    if show_timing:\n",
    "        print(f\"\\nTiming for {file_prefix}:\")\n",
    "        print(f\"  File loading: {load_time:.3f}s\")\n",
    "        print(f\"  Data processing: {process_time:.3f}s\")\n",
    "        print(f\"  Total time: {total_time:.3f}s\")\n",
    "        print(f\"  Interactions found: {len(df)}\")\n",
    "        print(f\"  Processing rate: {len(df)/total_time:.0f} interactions/sec\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_csv(df, filepath, include_metadata=True):\n",
    "    \"\"\"\n",
    "    Save DataFrame to CSV with optional metadata preservation.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame to save\n",
    "        filepath: path where to save the CSV\n",
    "        include_metadata: whether to save metadata as a separate file\n",
    "    \"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save main DataFrame\n",
    "    df.to_csv(filepath, index=False)\n",
    "    \n",
    "    # Save metadata if available and requested\n",
    "    if include_metadata and hasattr(df, 'attrs') and df.attrs:\n",
    "        metadata_file = filepath.with_suffix('.meta.json')\n",
    "        import json\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(df.attrs, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved DataFrame to {filepath}\")\n",
    "    if include_metadata:\n",
    "        print(f\"Saved metadata to {filepath.with_suffix('.meta.json')}\")\n",
    "\n",
    "def load_dataframe_from_csv(filepath, load_metadata=True):\n",
    "    \"\"\"\n",
    "    Load DataFrame from CSV with optional metadata restoration.\n",
    "    \n",
    "    Args:\n",
    "        filepath: path to the CSV file\n",
    "        load_metadata: whether to load metadata from separate file\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with restored metadata if available\n",
    "    \"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    \n",
    "    # Load main DataFrame\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Load metadata if available and requested\n",
    "    if load_metadata:\n",
    "        metadata_file = filepath.with_suffix('.meta.json')\n",
    "        if metadata_file.exists():\n",
    "            import json\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                df.attrs = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded DataFrame from {filepath}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Native Contacts Analyzer Class\n",
    "\n",
    "Comprehensive system for analyzing native hydrogen bond contacts over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NativeContactsAnalyzer:\n",
    "    \"\"\"\n",
    "    Comprehensive analysis system for native hydrogen bond contacts.\n",
    "    \n",
    "    - Loading runs individually and storing in indexed list\n",
    "    - CSV save/load functionality \n",
    "    - Native contacts identification from frame 0\n",
    "    - Time series analysis of native contacts preservation\n",
    "    - Plotting capabilities\n",
    "    \n",
    "    Note: From June 2024, `energy_fraction` is defined as:\n",
    "      (sum of energies of native contacts present in current frame) /\n",
    "      (sum of all hbond energies present in current frame above threshold)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, results_dir=\"results/\", csv_dir=\"results/csv_data/\"):\n",
    "        self.results_dir = Path(results_dir)\n",
    "        self.csv_dir = Path(csv_dir)\n",
    "        self.csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.runs_data = []  # List indexed by run number\n",
    "        self.native_contacts = None  # Native contacts from frame 0\n",
    "        self.native_contact_energies = None  # Native contact energies from frame 0\n",
    "    \n",
    "    def load_single_run(self, run_number: int, file_pattern=\"Kmarx_Pab1.run\", \n",
    "                       save_csv=True, show_timing=False):\n",
    "        \"\"\"\n",
    "        Load a single run and optionally save as CSV.\n",
    "        \n",
    "        Args:\n",
    "            run_number: run number to load\n",
    "            file_pattern: pattern for finding files\n",
    "            save_csv: whether to save DataFrame as CSV\n",
    "            show_timing: whether to show timing information\n",
    "        \"\"\"\n",
    "        file_prefix = f\"{file_pattern}.{run_number}\"\n",
    "        \n",
    "        try:\n",
    "            # Load the run\n",
    "            df = load_hbond_data_to_dataframe(file_prefix, self.results_dir, show_timing)\n",
    "            \n",
    "            # Ensure runs_data list is large enough\n",
    "            while len(self.runs_data) <= run_number:\n",
    "                self.runs_data.append(None)\n",
    "            \n",
    "            # Store in list at correct index\n",
    "            self.runs_data[run_number] = df\n",
    "            \n",
    "            # Save as CSV if requested\n",
    "            if save_csv:\n",
    "                csv_path = self.csv_dir / f\"run_{run_number:03d}.csv\"\n",
    "                save_dataframe_to_csv(df, csv_path)\n",
    "            \n",
    "            print(f\"Successfully loaded run {run_number} with {len(df)} interactions\")\n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Could not load run {run_number}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_all_runs(self, file_pattern=\"Kmarx_Pab1.run\", max_runs=None, \n",
    "                     save_csv=True, show_timing=False):\n",
    "        \"\"\"\n",
    "        Load all available runs.\n",
    "        \n",
    "        Args:\n",
    "            file_pattern: pattern for finding files\n",
    "            max_runs: maximum number of runs to load (None for all)\n",
    "            save_csv: whether to save DataFrames as CSV\n",
    "            show_timing: whether to show timing information\n",
    "        \"\"\"\n",
    "        # Find all available runs\n",
    "        npy_files = list(self.results_dir.glob(f\"{file_pattern}*_hbond_energy_maps.npy\"))\n",
    "        \n",
    "        # Extract run numbers\n",
    "        run_numbers = []\n",
    "        for f in npy_files:\n",
    "            prefix = f.stem.replace(\"_hbond_energy_maps\", \"\")\n",
    "            try:\n",
    "                run_num = int(prefix.split('.')[-1])\n",
    "                run_numbers.append(run_num)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        run_numbers.sort()\n",
    "        if max_runs:\n",
    "            run_numbers = run_numbers[:max_runs]\n",
    "            \n",
    "        print(f\"Found {len(run_numbers)} runs to load: {run_numbers}\")\n",
    "        \n",
    "        # Load each run\n",
    "        successful_loads = 0\n",
    "        for run_num in run_numbers:\n",
    "            df = self.load_single_run(run_num, file_pattern, save_csv, show_timing)\n",
    "            if df is not None:\n",
    "                successful_loads += 1\n",
    "        \n",
    "        print(f\"Successfully loaded {successful_loads} out of {len(run_numbers)} runs\")\n",
    "        return successful_loads\n",
    "    \n",
    "    def identify_native_contacts(self, run_number=0, energy_threshold=1e-6):\n",
    "        \"\"\"\n",
    "        Identify native contacts from frame 0 of a reference run.\n",
    "        \n",
    "        Args:\n",
    "            run_number: which run to use as reference (default: 0)\n",
    "            energy_threshold: minimum energy to consider a contact\n",
    "        \"\"\"\n",
    "        if run_number >= len(self.runs_data) or self.runs_data[run_number] is None:\n",
    "            raise ValueError(f\"Run {run_number} not loaded\")\n",
    "        \n",
    "        df = self.runs_data[run_number]\n",
    "        \n",
    "        # Get frame 0 data\n",
    "        frame_0 = df[df['frame'] == 0].copy()\n",
    "        \n",
    "        # Native contacts are residue pairs with energy > threshold at frame 0\n",
    "        native_pairs = frame_0[frame_0['hbond_energy'] > energy_threshold]\n",
    "        \n",
    "        # Store native contact pairs (set of tuples)\n",
    "        self.native_contacts = set()\n",
    "        for _, row in native_pairs.iterrows():\n",
    "            pair = (min(row['residue_i'], row['residue_j']), \n",
    "                   max(row['residue_i'], row['residue_j']))\n",
    "            self.native_contacts.add(pair)\n",
    "        \n",
    "        # Store native contact energies (dict of pair -> energy)\n",
    "        self.native_contact_energies = {}\n",
    "        for _, row in native_pairs.iterrows():\n",
    "            pair = (min(row['residue_i'], row['residue_j']), \n",
    "                   max(row['residue_i'], row['residue_j']))\n",
    "            self.native_contact_energies[pair] = row['hbond_energy']\n",
    "        \n",
    "        print(f\"Identified {len(self.native_contacts)} native contacts from run {run_number}, frame 0\")\n",
    "        print(f\"Total native contact energy: {sum(self.native_contact_energies.values()):.3f}\")\n",
    "        \n",
    "        return self.native_contacts, self.native_contact_energies\n",
    "    \n",
    "    def calculate_native_contacts_timeseries(self, run_number: int, energy_threshold=1e-6):\n",
    "        \"\"\"\n",
    "        Calculate native contacts preservation over time for a single run.\n",
    "\n",
    "        Args:\n",
    "            run_number: run to analyze\n",
    "            energy_threshold: minimum energy to consider a contact present\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with columns: frame, count_fraction, energy_fraction\n",
    "\n",
    "        energy_fraction = (sum of energies for native contacts in current frame) /\n",
    "                          (sum of all hbond energies in current frame > threshold)\n",
    "        \"\"\"\n",
    "        if self.native_contacts is None:\n",
    "            raise ValueError(\"Native contacts not identified. Run identify_native_contacts() first.\")\n",
    "        \n",
    "        if run_number >= len(self.runs_data) or self.runs_data[run_number] is None:\n",
    "            raise ValueError(f\"Run {run_number} not loaded\")\n",
    "        \n",
    "        df = self.runs_data[run_number]\n",
    "        \n",
    "        frames = sorted(df['frame'].unique())\n",
    "        results = []\n",
    "        \n",
    "        total_native_contacts = len(self.native_contacts)\n",
    "        \n",
    "        for frame in frames:\n",
    "            frame_data = df[df['frame'] == frame]\n",
    "            \n",
    "            # Get total energy in this frame above threshold (all contacts)\n",
    "            current_total_energy = frame_data.loc[\n",
    "                frame_data['hbond_energy'] > energy_threshold, 'hbond_energy'\n",
    "            ].sum()\n",
    "            \n",
    "            present_native_contacts = 0\n",
    "            current_native_energy = 0.0\n",
    "\n",
    "            # Check each native contact\n",
    "            for pair in self.native_contacts:\n",
    "                i, j = pair\n",
    "                # Look for this pair in current frame\n",
    "                contact_rows = frame_data[\n",
    "                    ((frame_data['residue_i'] == i) & (frame_data['residue_j'] == j)) |\n",
    "                    ((frame_data['residue_i'] == j) & (frame_data['residue_j'] == i))\n",
    "                ]\n",
    "                if not contact_rows.empty:\n",
    "                    max_energy = contact_rows['hbond_energy'].max()\n",
    "                    if max_energy > energy_threshold:\n",
    "                        present_native_contacts += 1\n",
    "                        current_native_energy += max_energy\n",
    "\n",
    "            # Calculate fractions\n",
    "            count_fraction = (\n",
    "                present_native_contacts / total_native_contacts\n",
    "                if total_native_contacts > 0 else 0\n",
    "            )\n",
    "            energy_fraction = (\n",
    "                current_native_energy / current_total_energy\n",
    "                if current_total_energy > 0 else 0\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'frame': frame,\n",
    "                'count_fraction': count_fraction,\n",
    "                'energy_fraction': energy_fraction,\n",
    "                'run_id': run_number\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def calculate_all_native_contacts_timeseries(self, energy_threshold=1e-6):\n",
    "        \"\"\"\n",
    "        Calculate native contacts preservation for all loaded runs.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with all runs' timeseries data\n",
    "        \"\"\"\n",
    "        if self.native_contacts is None:\n",
    "            raise ValueError(\"Native contacts not identified. Run identify_native_contacts() first.\")\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        for run_num, df in enumerate(self.runs_data):\n",
    "            if df is not None:\n",
    "                print(f\"Processing run {run_num}...\")\n",
    "                run_results = self.calculate_native_contacts_timeseries(run_num, energy_threshold)\n",
    "                all_results.append(run_results)\n",
    "        \n",
    "        if not all_results:\n",
    "            raise ValueError(\"No runs loaded\")\n",
    "        \n",
    "        combined_df = pd.concat(all_results, ignore_index=True)\n",
    "        return combined_df\n",
    "    \n",
    "    def plot_native_contacts_timeseries(self, timeseries_df=None, save_path=None, \n",
    "                                       figsize=(12, 8), show_individual_runs=True):\n",
    "        \"\"\"\n",
    "        Plot native contacts preservation over time.\n",
    "        \n",
    "        Args:\n",
    "            timeseries_df: DataFrame with timeseries data (if None, calculates it)\n",
    "            save_path: path to save figure. You can use '{run_id}' as a placeholder in the path.\n",
    "            figsize: figure size\n",
    "            show_individual_runs: whether to show individual run traces\n",
    "        \"\"\"\n",
    "        if timeseries_df is None:\n",
    "            timeseries_df = self.calculate_all_native_contacts_timeseries()\n",
    "        \n",
    "        run_ids = timeseries_df['run_id'].unique()\n",
    "        is_single_run = len(run_ids) == 1\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "        \n",
    "        # Plot 1: Count-based native contacts\n",
    "        if show_individual_runs:\n",
    "            # Show individual runs\n",
    "            for run_id in run_ids:\n",
    "                run_data = timeseries_df[timeseries_df['run_id'] == run_id]\n",
    "                ax1.plot(run_data['frame'], run_data['count_fraction'] * 100, \n",
    "                        alpha=0.3, linewidth=0.8, color='blue')\n",
    "        \n",
    "        # Show average\n",
    "        avg_count = timeseries_df.groupby('frame')['count_fraction'].mean()\n",
    "        std_count = timeseries_df.groupby('frame')['count_fraction'].std()\n",
    "        frames = avg_count.index\n",
    "        \n",
    "        ax1.plot(frames, avg_count * 100, 'b-', linewidth=2, label='Average')\n",
    "        ax1.fill_between(frames, (avg_count - std_count) * 100, (avg_count + std_count) * 100, \n",
    "                        alpha=0.2, color='blue')\n",
    "        \n",
    "        ax1.set_ylabel('% Native Contacts (Count)', fontsize=12)\n",
    "        ax1.set_title('Native Hydrogen Bond Contacts Over Time', fontsize=14)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Plot 2: Energy-based native contacts\n",
    "        if show_individual_runs:\n",
    "            # Show individual runs\n",
    "            for run_id in run_ids:\n",
    "                run_data = timeseries_df[timeseries_df['run_id'] == run_id]\n",
    "                ax2.plot(run_data['frame'], run_data['energy_fraction'] * 100, \n",
    "                        alpha=0.3, linewidth=0.8, color='red')\n",
    "        \n",
    "        # Show average\n",
    "        avg_energy = timeseries_df.groupby('frame')['energy_fraction'].mean()\n",
    "        std_energy = timeseries_df.groupby('frame')['energy_fraction'].std()\n",
    "        \n",
    "        ax2.plot(frames, avg_energy * 100, 'r-', linewidth=2, label='Average')\n",
    "        ax2.fill_between(frames, (avg_energy - std_energy) * 100, (avg_energy + std_energy) * 100, \n",
    "                        alpha=0.2, color='red')\n",
    "        \n",
    "        ax2.set_xlabel('Frame', fontsize=12)\n",
    "        ax2.set_ylabel('% Native Contacts (Energy)', fontsize=12)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # ----- Save logic with run id -----\n",
    "        if save_path:\n",
    "            save_path = str(save_path)\n",
    "            if '{run_id}' in save_path:\n",
    "                # Save separate figure for each run if plotting single run,\n",
    "                # or 'all' if plotting the combined average\n",
    "                if is_single_run:\n",
    "                    current_run_id = run_ids[0]\n",
    "                else:\n",
    "                    current_run_id = 'all'\n",
    "                actual_save_path = save_path.replace('{run_id}', str(current_run_id))\n",
    "            else:\n",
    "                # Append run id or 'all' before file extension if not present\n",
    "                p = Path(save_path)\n",
    "                if is_single_run:\n",
    "                    actual_save_path = str(p.with_name(f\"{p.stem}_run{run_ids[0]}{p.suffix}\"))\n",
    "                else:\n",
    "                    actual_save_path = str(p.with_name(f\"{p.stem}_all{p.suffix}\"))\n",
    "            plt.savefig(actual_save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Saved plot to {actual_save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 runs to load: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "Saved DataFrame to results/csv_data/run_000.csv\n",
      "Saved metadata to results/csv_data/run_000.meta.json\n",
      "Successfully loaded run 0 with 81640 interactions\n",
      "Saved DataFrame to results/csv_data/run_001.csv\n",
      "Saved metadata to results/csv_data/run_001.meta.json\n",
      "Successfully loaded run 1 with 86314 interactions\n",
      "Saved DataFrame to results/csv_data/run_002.csv\n",
      "Saved metadata to results/csv_data/run_002.meta.json\n",
      "Successfully loaded run 2 with 82438 interactions\n",
      "Saved DataFrame to results/csv_data/run_003.csv\n",
      "Saved metadata to results/csv_data/run_003.meta.json\n",
      "Successfully loaded run 3 with 82189 interactions\n",
      "Saved DataFrame to results/csv_data/run_004.csv\n",
      "Saved metadata to results/csv_data/run_004.meta.json\n",
      "Successfully loaded run 4 with 80426 interactions\n",
      "Saved DataFrame to results/csv_data/run_005.csv\n",
      "Saved metadata to results/csv_data/run_005.meta.json\n",
      "Successfully loaded run 5 with 82729 interactions\n",
      "Saved DataFrame to results/csv_data/run_006.csv\n",
      "Saved metadata to results/csv_data/run_006.meta.json\n",
      "Successfully loaded run 6 with 81954 interactions\n",
      "Saved DataFrame to results/csv_data/run_007.csv\n",
      "Saved metadata to results/csv_data/run_007.meta.json\n",
      "Successfully loaded run 7 with 77092 interactions\n",
      "Saved DataFrame to results/csv_data/run_008.csv\n",
      "Saved metadata to results/csv_data/run_008.meta.json\n",
      "Successfully loaded run 8 with 80564 interactions\n",
      "Saved DataFrame to results/csv_data/run_009.csv\n",
      "Saved metadata to results/csv_data/run_009.meta.json\n",
      "Successfully loaded run 9 with 83049 interactions\n",
      "Saved DataFrame to results/csv_data/run_010.csv\n",
      "Saved metadata to results/csv_data/run_010.meta.json\n",
      "Successfully loaded run 10 with 81736 interactions\n",
      "Saved DataFrame to results/csv_data/run_011.csv\n",
      "Saved metadata to results/csv_data/run_011.meta.json\n",
      "Successfully loaded run 11 with 81039 interactions\n",
      "Saved DataFrame to results/csv_data/run_012.csv\n",
      "Saved metadata to results/csv_data/run_012.meta.json\n",
      "Successfully loaded run 12 with 86295 interactions\n",
      "Saved DataFrame to results/csv_data/run_013.csv\n",
      "Saved metadata to results/csv_data/run_013.meta.json\n",
      "Successfully loaded run 13 with 77490 interactions\n",
      "Saved DataFrame to results/csv_data/run_014.csv\n",
      "Saved metadata to results/csv_data/run_014.meta.json\n",
      "Successfully loaded run 14 with 81301 interactions\n",
      "Saved DataFrame to results/csv_data/run_015.csv\n",
      "Saved metadata to results/csv_data/run_015.meta.json\n",
      "Successfully loaded run 15 with 80057 interactions\n",
      "Saved DataFrame to results/csv_data/run_016.csv\n",
      "Saved metadata to results/csv_data/run_016.meta.json\n",
      "Successfully loaded run 16 with 84534 interactions\n",
      "Saved DataFrame to results/csv_data/run_017.csv\n",
      "Saved metadata to results/csv_data/run_017.meta.json\n",
      "Successfully loaded run 17 with 78803 interactions\n",
      "Saved DataFrame to results/csv_data/run_018.csv\n",
      "Saved metadata to results/csv_data/run_018.meta.json\n",
      "Successfully loaded run 18 with 82487 interactions\n",
      "Saved DataFrame to results/csv_data/run_019.csv\n",
      "Saved metadata to results/csv_data/run_019.meta.json\n",
      "Successfully loaded run 19 with 78544 interactions\n",
      "Saved DataFrame to results/csv_data/run_020.csv\n",
      "Saved metadata to results/csv_data/run_020.meta.json\n",
      "Successfully loaded run 20 with 79621 interactions\n",
      "Saved DataFrame to results/csv_data/run_021.csv\n",
      "Saved metadata to results/csv_data/run_021.meta.json\n",
      "Successfully loaded run 21 with 83150 interactions\n",
      "Saved DataFrame to results/csv_data/run_022.csv\n",
      "Saved metadata to results/csv_data/run_022.meta.json\n",
      "Successfully loaded run 22 with 80889 interactions\n",
      "Saved DataFrame to results/csv_data/run_023.csv\n",
      "Saved metadata to results/csv_data/run_023.meta.json\n",
      "Successfully loaded run 23 with 78765 interactions\n",
      "Saved DataFrame to results/csv_data/run_024.csv\n",
      "Saved metadata to results/csv_data/run_024.meta.json\n",
      "Successfully loaded run 24 with 79605 interactions\n",
      "Saved DataFrame to results/csv_data/run_025.csv\n",
      "Saved metadata to results/csv_data/run_025.meta.json\n",
      "Successfully loaded run 25 with 81051 interactions\n",
      "Saved DataFrame to results/csv_data/run_026.csv\n",
      "Saved metadata to results/csv_data/run_026.meta.json\n",
      "Successfully loaded run 26 with 79486 interactions\n",
      "Saved DataFrame to results/csv_data/run_027.csv\n",
      "Saved metadata to results/csv_data/run_027.meta.json\n",
      "Successfully loaded run 27 with 82322 interactions\n",
      "Saved DataFrame to results/csv_data/run_028.csv\n",
      "Saved metadata to results/csv_data/run_028.meta.json\n",
      "Successfully loaded run 28 with 79833 interactions\n",
      "Saved DataFrame to results/csv_data/run_029.csv\n",
      "Saved metadata to results/csv_data/run_029.meta.json\n",
      "Successfully loaded run 29 with 76327 interactions\n",
      "Saved DataFrame to results/csv_data/run_030.csv\n",
      "Saved metadata to results/csv_data/run_030.meta.json\n",
      "Successfully loaded run 30 with 74495 interactions\n",
      "Saved DataFrame to results/csv_data/run_031.csv\n",
      "Saved metadata to results/csv_data/run_031.meta.json\n",
      "Successfully loaded run 31 with 75154 interactions\n",
      "Saved DataFrame to results/csv_data/run_032.csv\n",
      "Saved metadata to results/csv_data/run_032.meta.json\n",
      "Successfully loaded run 32 with 79649 interactions\n",
      "Saved DataFrame to results/csv_data/run_033.csv\n",
      "Saved metadata to results/csv_data/run_033.meta.json\n",
      "Successfully loaded run 33 with 79299 interactions\n",
      "Saved DataFrame to results/csv_data/run_034.csv\n",
      "Saved metadata to results/csv_data/run_034.meta.json\n",
      "Successfully loaded run 34 with 75814 interactions\n",
      "Saved DataFrame to results/csv_data/run_035.csv\n",
      "Saved metadata to results/csv_data/run_035.meta.json\n",
      "Successfully loaded run 35 with 75748 interactions\n",
      "Saved DataFrame to results/csv_data/run_036.csv\n",
      "Saved metadata to results/csv_data/run_036.meta.json\n",
      "Successfully loaded run 36 with 76553 interactions\n",
      "Saved DataFrame to results/csv_data/run_037.csv\n",
      "Saved metadata to results/csv_data/run_037.meta.json\n",
      "Successfully loaded run 37 with 70535 interactions\n",
      "Saved DataFrame to results/csv_data/run_038.csv\n",
      "Saved metadata to results/csv_data/run_038.meta.json\n",
      "Successfully loaded run 38 with 76167 interactions\n",
      "Saved DataFrame to results/csv_data/run_039.csv\n",
      "Saved metadata to results/csv_data/run_039.meta.json\n",
      "Successfully loaded run 39 with 75728 interactions\n",
      "Saved DataFrame to results/csv_data/run_040.csv\n",
      "Saved metadata to results/csv_data/run_040.meta.json\n",
      "Successfully loaded run 40 with 73630 interactions\n",
      "Saved DataFrame to results/csv_data/run_041.csv\n",
      "Saved metadata to results/csv_data/run_041.meta.json\n",
      "Successfully loaded run 41 with 73276 interactions\n",
      "Saved DataFrame to results/csv_data/run_042.csv\n",
      "Saved metadata to results/csv_data/run_042.meta.json\n",
      "Successfully loaded run 42 with 77317 interactions\n",
      "Saved DataFrame to results/csv_data/run_043.csv\n",
      "Saved metadata to results/csv_data/run_043.meta.json\n",
      "Successfully loaded run 43 with 74307 interactions\n",
      "Saved DataFrame to results/csv_data/run_044.csv\n",
      "Saved metadata to results/csv_data/run_044.meta.json\n",
      "Successfully loaded run 44 with 69975 interactions\n",
      "Saved DataFrame to results/csv_data/run_045.csv\n",
      "Saved metadata to results/csv_data/run_045.meta.json\n",
      "Successfully loaded run 45 with 74265 interactions\n",
      "Saved DataFrame to results/csv_data/run_046.csv\n",
      "Saved metadata to results/csv_data/run_046.meta.json\n",
      "Successfully loaded run 46 with 74357 interactions\n"
     ]
    }
   ],
   "source": [
    "# Create analyzer instance\n",
    "analyzer = NativeContactsAnalyzer()\n",
    "\n",
    "# Load all available runs (this will save CSVs automatically)\n",
    "analyzer.load_all_runs(max_runs=48)  # Limit to first 5 runs for testing\n",
    "\n",
    "# Identify native contacts from run 0, frame 0\n",
    "analyzer.identify_native_contacts(run_number=0)\n",
    "\n",
    "# Calculate time series for all runs\n",
    "timeseries_data = analyzer.calculate_all_native_contacts_timeseries()\n",
    "\n",
    "# Plot the results\n",
    "analyzer.plot_native_contacts_timeseries(timeseries_data, \n",
    "                                        save_path=\"results/native_contacts_timeseries.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Load individual runs\n",
    "# analyzer = NativeContactsAnalyzer()\n",
    "# analyzer.load_single_run(0, show_timing=True)\n",
    "# analyzer.load_single_run(1, show_timing=True)\n",
    "# analyzer.load_single_run(2, show_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from saved CSV files\n",
    "# analyzer = NativeContactsAnalyzer()\n",
    "# analyzer.load_run_from_csv(0)\n",
    "# analyzer.load_run_from_csv(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "# summary = analyzer.get_summary_statistics(timeseries_data)\n",
    "# print(\"Summary Statistics:\")\n",
    "# for key, value in summary.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
